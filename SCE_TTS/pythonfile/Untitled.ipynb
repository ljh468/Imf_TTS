{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb573e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GPU_NAME = os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read().strip()\n",
    "os.environ['GPU_NAME'] = GPU_NAME\n",
    "print(f'GPU: {GPU_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14583347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ad58bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.9.1\n",
      "cuda version: 11.1\n",
      "cudnn version:8005\n",
      "True\n",
      "GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__))\n",
    "print(\"cuda version: {}\".format(torch.version.cuda))\n",
    "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67561451",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/User/Desktop/SCE_TTS/TTS/test_sentences.txt\", mode=\"w\") as f:\n",
    "    f.write(\"\"\"아래 문장들은 모델 학습을 위해 사용하지 않은 문장들입니다.\n",
    "서울특별시 특허허가과 허가과장 허과장.\n",
    "경찰청 철창살은 외철창살이고 검찰청 철창살은 쌍철창살이다.\n",
    "지향을 지양으로 오기하는 일을 지양하는 언어 습관을 지향해야 한다.\n",
    "그러니까 외계인이 우리 생각을 읽고 우리 생각을 우리가 다시 생각토록 해서 그 생각이 마치 우리가 생각한 것인 것처럼 속였다는 거냐?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5e4532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6adfb25f212628b6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6adfb25f212628b6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967d9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\SCE_TTS\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/User/Desktop/SCE_TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43730fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Git Hash: 0000000\n",
      " > Experiment folder: C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/glowtts-v2-November-01-2021_11+30AM-0000000\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "c:\\users\\user\\desktop\\sce_tts\\tts\\TTS\\tts\\layers\\glow_tts\\glow.py:84: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:1940.)\n",
      "  w_init = torch.qr(torch.FloatTensor(self.num_splits, self.num_splits).normal_())[0]\n",
      "C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Traceback (most recent call last):\n",
      "  File \"TTS/TTS/bin/train_glow_tts.py\", line 588, in <module>\n",
      "    main(args)\n",
      "  File \"TTS/TTS/bin/train_glow_tts.py\", line 562, in main\n",
      "    train_loader, model, criterion, optimizer, scheduler, ap, global_step, epoch\n",
      "  File \"TTS/TTS/bin/train_glow_tts.py\", line 215, in train\n",
      "    loss_dict[\"loss\"].backward()\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\_tensor.py\", line 255, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 149, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > preemphasis:0.98\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > stats_path:C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 12854 files in C:\\Users\\User\\Desktop\\SCE_TTS\\data\\filelists\n",
      " > Using model: glow_tts\n",
      " > Restoring from model_file.pth.tar ...\n",
      " > Model restored from step 26000\n",
      "\n",
      " > Model has 28612177 parameters\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Starting with inf best loss.\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Use phonemes: False\n",
      " | > Number of instances : 12726\n",
      " | > Max length sequence: 52\n",
      " | > Min length sequence: 2\n",
      " | > Avg length sequence: 19.677196291057676\n",
      " | > Num. instances discarded by max-min (max=500, min=3) seq limits: 2\n",
      " | > Batch group size: 128.\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Use phonemes: False\n",
      " | > Number of instances : 128\n",
      " | > Max length sequence: 43\n",
      " | > Min length sequence: 6\n",
      " | > Avg length sequence: 18.765625\n",
      " | > Num. instances discarded by max-min (max=500, min=3) seq limits: 0\n",
      " | > Batch group size: 0.\n",
      " > Data depended initialization ... \n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/10000\u001b[0m\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      "\n",
      "\u001b[1m > TRAINING (2021-11-01 11:30:42) \u001b[0m\n",
      " ! Run is removed from C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/glowtts-v2-November-01-2021_11+30AM-0000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: cusolver error: CUSOLVER_STATUS_INTERNAL_ERROR, when calling `cusolverDnCreate(handle)`\n"
     ]
    }
   ],
   "source": [
    "!python TTS/TTS/bin/train_glow_tts.py \\\n",
    "--config_path \"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/config.json\" \\\n",
    "--coqpit.datasets.0.path \"C:/Users/User/Desktop/SCE_TTS/data/filelists\" \\\n",
    "--coqpit.audio.stats_path \"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/scale_stats.npy\" \\\n",
    "--coqpit.test_sentences_file \"C:/Users/User/Desktop/SCE_TTS/TTS/test_sentences.txt\" \\\n",
    "--coqpit.output_path \"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/\" \\\n",
    "--coqpit.num_loader_workers 2 \\\n",
    "--coqpit.num_val_loader_workers 2 \\\n",
    "--restore_path \"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/model_file.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0474886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\SCE_TTS\\TTS\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.1\n",
      " | > preemphasis:0.98\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > stats_path:C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/glowtts-v2-October-13-2021_09+09AM-3aa165a/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 12854 files in C:\\Users\\User\\Desktop\\SCE_TTS\\data\\filelists\n",
      " > Using model: glow_tts\n",
      " > Restoring from checkpoint_75000.pth.tar ...\n",
      " > Model restored from step 75000\n",
      "\n",
      " > Model has 28612177 parameters\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Restoring best loss from best_model.pth.tar ...\n",
      " > Starting with loaded last best loss -0.7771029557500567.\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Use phonemes: False\n",
      " | > Number of instances : 12726\n",
      " | > Max length sequence: 52\n",
      " | > Min length sequence: 2\n",
      " | > Avg length sequence: 19.677196291057676\n",
      " | > Num. instances discarded by max-min (max=500, min=3) seq limits: 2\n",
      " | > Batch group size: 128.\n",
      "\n",
      " > DataLoader initialization\n",
      " | > Use phonemes: False\n",
      " | > Number of instances : 128\n",
      " | > Max length sequence: 43\n",
      " | > Min length sequence: 6\n",
      " | > Avg length sequence: 18.765625\n",
      " | > Num. instances discarded by max-min (max=500, min=3) seq limits: 0\n",
      " | > Batch group size: 0.\n",
      " > Data depended initialization ... \n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/10000\u001b[0m\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      " > Using CUDA:  True\n",
      " > Number of GPUs:  1\n",
      "\n",
      "\u001b[1m > TRAINING (2021-11-01 11:34:29) \u001b[0m\n",
      " ! Run is kept in C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/glowtts-v2-October-13-2021_09+09AM-3aa165a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\sce_tts\\tts\\TTS\\tts\\layers\\glow_tts\\glow.py:84: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:1940.)\n",
      "  w_init = torch.qr(torch.FloatTensor(self.num_splits, self.num_splits).normal_())[0]\n",
      "C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Traceback (most recent call last):\n",
      "  File \"TTS/bin/train_glow_tts.py\", line 588, in <module>\n",
      "    main(args)\n",
      "  File \"TTS/bin/train_glow_tts.py\", line 562, in main\n",
      "    train_loader, model, criterion, optimizer, scheduler, ap, global_step, epoch\n",
      "  File \"TTS/bin/train_glow_tts.py\", line 215, in train\n",
      "    loss_dict[\"loss\"].backward()\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\_tensor.py\", line 255, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\hkcloud\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 149, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/User/Desktop/SCE_TTS/TTS\n",
    "!(python TTS/bin/train_glow_tts.py \\\n",
    "    --continue_path \"C:/Users/User/Desktop/SCE_TTS/data/glowtts-v2/glowtts-v2-October-13-2021_09+09AM-3aa165a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3a5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkcloud",
   "language": "python",
   "name": "hkcloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
